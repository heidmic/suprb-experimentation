{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris,load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the dataset inspection!\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "loaded_data = pd.read_csv('abalone.csv')\n",
    "data = loaded_data.drop(columns=['Rings'])\n",
    "target = loaded_data['Rings']\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = data.select_dtypes(include='object').columns\n",
    "\n",
    "transformer = make_column_transformer(((OneHotEncoder(sparse=False)), categorical_cols),remainder='passthrough')\n",
    "# transforming\n",
    "data_array = transformer.fit_transform(data)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_array, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Data Exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the dataset to understand its structure and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of datapoints (row in a dataframe)\n",
    "print(data.shape)\n",
    "\n",
    "# Class distribution for a classification problem\n",
    "\n",
    "# Calculate unique values and their count\n",
    "unique_values, counts = np.unique(target, return_counts=True)\n",
    "class_distribution = dict(zip(unique_values, counts))\n",
    "print(\"Class distribution:\")\n",
    "print(class_distribution)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Get basic statistics of the dataset\n",
    "print(\"\\nBasic statistics of the dataset:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Display dataset information\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram for numeric columns only\n",
    "for col in numeric_cols:\n",
    "    data[col].plot.hist(bins=100)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Histogram of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the distribution of the feature\n",
    "\n",
    "import scipy\n",
    "feature = None\n",
    "#feature = data[\"x14\"]\n",
    "if feature is not None:\n",
    "    kurtosis = scipy.stats.kurtosis(feature)\n",
    "    skew = scipy.stats.skew(feature)\n",
    "    median = np.median(feature)\n",
    "    std = np.std(feature)\n",
    "    print(f\"Kurtosis: {kurtosis}\")\n",
    "    print(f\"Skew: {skew}\")\n",
    "    print(f\"Median: {median}\")\n",
    "    print(f\"Standard Deviation: {std}\")\n",
    "    scipy.stats.normaltest(feature)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's preprocess the data. \n",
    "\n",
    "We'll handle missing values (if any), \n",
    "\n",
    "encode categorical features (if any),\n",
    "\n",
    "and scale numeric features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values and handle them (if any)\n",
    "## FYI: some algorithms do not handle the data having missing values except Tree-based models.\n",
    "\n",
    "data.isna().sum()\n",
    "# Scale numeric features using StandardScaler\n",
    "## FYI: some of the Machine learning algorithm require and benefit from the data to be in a specific range such as Neural networks, SVMs, K-means clustering, PCA, and Logistic regression.\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Model creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now create and train different classification models using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a Logistic Regression classifier\n",
    "logistic_regression = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logistic_regression.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a Random Forest classifier\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create and train a Support Vector Machine (SVM) classifier\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Model Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the models on the testing data using various evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the Logistic Regression classifier\n",
    "y_pred_lr = logistic_regression.predict(X_test_scaled)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "recall_lr = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "print(\"Logistic Regression:\")\n",
    "print(f\"Accuracy: {accuracy_lr}\")\n",
    "print(f\"Precision: {precision_lr}\")\n",
    "print(f\"Recall: {recall_lr}\")\n",
    "print(f\"F1 Score: {f1_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Decision Tree model\n",
    "y_pred_dt = decision_tree.predict(X_test_scaled)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt, average='weighted')\n",
    "recall_dt = recall_score(y_test, y_pred_dt, average='weighted')\n",
    "f1_dt = f1_score(y_test, y_pred_dt, average='weighted')\n",
    "\n",
    "print(\"Decision Tree Model:\")\n",
    "print(f\"Accuracy: {accuracy_dt}\")\n",
    "print(f\"Precision: {precision_dt}\")\n",
    "print(f\"Recall: {recall_dt}\")\n",
    "print(f\"F1 Score: {f1_dt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Random Forest model\n",
    "y_pred_rf = random_forest.predict(X_test_scaled)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf, average='weighted')\n",
    "recall_rf = recall_score(y_test, y_pred_rf, average='weighted')\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "print(\"\\nRandom Forest Model:\")\n",
    "print(f\"Accuracy: {accuracy_rf}\")\n",
    "print(f\"Precision: {precision_rf}\")\n",
    "print(f\"Recall: {recall_rf}\")\n",
    "print(f\"F1 Score: {f1_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Support Vector Machine (SVM) model\n",
    "y_pred_svm = svm.predict(X_test_scaled)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm, average='weighted')\n",
    "recall_svm = recall_score(y_test, y_pred_svm, average='weighted')\n",
    "f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "\n",
    "print(\"\\nSupport Vector Machine (SVM) Model:\")\n",
    "print(f\"Accuracy: {accuracy_svm}\")\n",
    "print(f\"Precision: {precision_svm}\")\n",
    "print(f\"Recall: {recall_svm}\")\n",
    "print(f\"F1 Score: {f1_svm}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
